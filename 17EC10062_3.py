# -*- coding: utf-8 -*-
"""adaboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xMMd56OIKe_boG-xeIBHbqLP8lTeQFT9
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.

# -*- coding: utf-8 -*-
"""17EC10062_Assignment3
Automatically generated by Colaboratory.

"""

# import pandas as pd
import numpy as np
eps = np.finfo(float).eps
from numpy import log2 as log

from numpy import genfromtxt
from random import randint
from random import random
from random import randrange
from numpy.random import choice

#import pandas as pd
data = genfromtxt('../input/data3_19.csv', delimiter=',',dtype=str)#for kaggle
test = genfromtxt('../input/test3_19.csv', delimiter=',',dtype=str)#for kaggle
dataset = pd.read_csv("../input/data3_19.csv")
dataset_test = pd.read_csv("../input/test3_19.csv")
dataset_test.columns = dataset.columns

# from sklearn.model_selection import train_test_split
# df_train, df_test = train_test_split(dataset, test_size=0.3)
# df_train = df_train.reset_index().drop('index', axis=1)
# df_test = df_test.reset_index().drop('index', axis=1)

# dataset = df_train
# dataset_test = df_test
# df_test['survived'].value_counts()

# j = np.array(choice(range(0, dataset.shape[0]), 500))
# l = list(dataset.index)
# for i in j:
#     try:
# #         print()
#         l.remove(i)
#     except:
#         print(dataset.iloc[i, :])
# l



from numpy.random import choice
from numpy import genfromtxt
# my_data = genfromtxt('../input/data3_19.csv', delimiter=',',dtype=str)#for kaggle
# my_data = dataset
# my_data = genfromtxt('../content/data1_19.csv', delimiter=',',dtype=str)#for colab

# print("data : \n", my_data)

# df = my_data[1:]

# print("shape : ", df[:, 1].shape)

def entropy(target_col):

    elements,counts = np.unique(target_col,return_counts = True)
    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])
    return entropy

# data = df
# data[data[:, 0]=='1st']

np.argmax(np.unique(data[:, 0],return_counts=True)[1])

# print(df)

########iNFO GAIN
def InfoGain(data,split_attribute_name,target_name=3):
    
    """
    Calculate the information gain of a dataset. This function takes three parameters:
    1. data = The dataset for whose feature the IG should be calculated
    2. split_attribute_name = the name of the feature for which the information gain should be calculated
    3. target_name = the name of the target feature. The default for this example is "class"
    """
    
    #Calculate the entropy of the total dataset
    total_entropy = entropy(data[:, target_name])
    
    ##Calculate the entropy of the dataset
    
    #Calculate the values and the corresponding counts for the split attribute 
    vals,counts= np.unique(data[:, split_attribute_name],return_counts=True)
    
    #Calculate the weighted entropy
    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data[data[:, split_attribute_name]==vals[i]][:, target_name]) for i in range(len(vals))])
    
    #Calculate the information gain
    Information_Gain = total_entropy - Weighted_Entropy
    return Information_Gain

f=['pclass','age','gender']

###################
from pprint import pprint

###################
def BUILD_tree(data,originaldata,features,target_attribute_name=3,parent_node_class = None):
    if len(np.unique(data[:, target_attribute_name])) <= 1:
        return np.unique(data[:, target_attribute_name])[0]
    elif len(data)==0:
        return np.unique(originaldata[:, target_attribute_name])[np.argmax(np.unique(originaldata[:, target_attribute_name],return_counts=True)[1])]
    elif len(features) ==0:
        return parent_node_class
    else:
        parent_node_class = np.unique(data[:, target_attribute_name])[np.argmax(np.unique(data[:, target_attribute_name],return_counts=True)[1])]
        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset
        best_feature_index = np.argmax(item_values)
        best_feature = features[best_feature_index]
        tree = {f[best_feature]:{}}
        features = [i for i in features if i != best_feature]        
        for value in np.unique(data[:, best_feature]):
            value = value
            sub_data = data[data[:, best_feature] == value]            
            subtree = BUILD_tree(sub_data , originaldata,features,target_attribute_name,parent_node_class)
            tree[f[best_feature]][ value] = subtree
        return(tree)

# training_data = df
# dataset = df

# tree = BUILD_tree(training_data,training_data, [0, 1, 2])
# pprint(tree)
def predict(query,tree,default = 1):
    #1.
    for key in list(query.keys()):
        if key in list(tree.keys()):
            #2.
            try:
                result = tree[key][query[key]] 
            except:
                return default
            #3.
            result = tree[key][query[key]]
            #4.
            if isinstance(result,dict):
                return predict(query,result)
            else:
                return result

def test_tree(data,tree):
    #Create new query instances by simply removing the target feature column from the original dataset and 
    #convert it to a dictionary
    queries = data.iloc[:,:-1].to_dict(orient = "records")
    #Create a empty DataFrame in whose columns the prediction of the tree are stored
    predicted = pd.DataFrame(columns=["predicted"]) 
    #Calculate the prediction accuracy
    for i in range(len(data)):
        predicted.loc[i,"predicted"] = predict(queries[i],tree,1.0) 
    print('The prediction accuracy on train is: ',(np.sum(np.array(predicted["predicted"]) == np.array(data["survived"]))/len(data))*100,'%')
    return np.array(predicted['predicted'])

# test_tree(dataset_test, tree)

# dataset = pd.read_csv("../input/data3_19.csv")
# dataset_test = pd.read_csv("../input/test3_19.csv")
# dataset_test.columns = dataset.columns

weights = [1/len(dataset)]*len(dataset) # Set the initial weights w = 1/N
'''        
            XX = dataset.iloc[:, :]
            summ=0
            p=[]
            for i in range(len(XX)):
                p.append(i)
                summ+=weights[i]
            for i in range(len(weights)):
                weights[i] /=summ
            k = len(XX)

            J = np.random.choice(p, k, True, weights)
            X = XX.iloc[J, :]
            Y = XX.iloc[J, -1]
            model = BUILD_tree(np.array(X),np.array(X), [0, 1, 2])
            p=test_tree(X, model)
            p[0]
            m=np.where(p!=Y,1,0)
            m

p[0]
'''
class Boosting:
    def __init__(self,dataset,T,test_dataset):
        pd_data =  dataset
        pd_test = test_dataset
#         dataset = np.array(dataset)
#         test_dataset = np.array(test_dataset)
        self.dataset = dataset
        self.T = T
        self.test_dataset = test_dataset
        self.alphas = None
        self.models = None
        self.accuracy = []
        self.predictions = None
    
    def fit(self):
        
        # Set the descriptive features and the target feature
        #X = self.dataset.iloc[:, :-1]
        #print(len(X))
        #Y = self.dataset.iloc[:, -1]
#         Y[Y=='yes'] = 1
#         Y[Y=='no'] = 0
#         print(len(Y))
        # Initialize the weights of each sample with wi = 1/N and create a dataframe in which the evaluation is computed
        #Evaluation = pd.DataFrame(Y.copy())
        #Evaluation = (Y.copy())
        #Evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N
        weights = np.array([1/len(self.dataset)]*len(self.dataset)) # Set the initial weights w = 1/N
        
        # Run the boosting algorithm by creating T "weighted models"
        
        alphas = []
        models = []
        t=0
        while(t< self.T):
            print(t)
#         for t in range(self.T):
#             print(t)
            # Train the Decision Stump(s)
            
#             Tree_model = DecisionTreeClassifier(criterion="entropy",max_depth=3) # Mind the deth one --> Decision Stump

            # We know that we must train our decision stumps on weighted datasets where the weights depend on the results of
            # the previous decision stumps. To accomplish that, we use the 'weights' column of the above created 
            # 'evaluation dataframe' together with the sample_weight parameter of the fit method.
            # The documentation for the sample_weights parameter sais: "[...] If None, then samples are equally weighted."
            # Consequently, if NOT None, then the samples are NOT equally weighted and therewith we create a WEIGHTED dataset 
            # which is exactly what we want to have.
            XX = self.dataset.iloc[:, :]
            summ=0
            p=[]
            for i in range(len(XX)):
                p.append(i)
            
            sumw=sum(weights)
            weights/=sumw
            k = len(XX)

            J = choice(p, k, True, weights)
            X = XX.iloc[J, :]
            idx=np.array(X.index)
            Y = np.array(XX.iloc[J, -1])
            model = BUILD_tree(np.array(X),np.array(X), [0, 1, 2])

#             model = BUILD_tree(training_data,training_data, [0, 1, 2])
#             model = Tree_model.fit(X,Y)

        #     # Append the single weak classifiers to a list which is later on used to make the 
        #     # weighted decision
            models.append(model)
            predictions = test_tree(X, model)
#             predictions = model.predict(X)
#             score = model.score(X,Y)
        #     # Add values to the Evaluation DataFrame
#             Evaluation['predictions'] = predictions
#             evaluation = np.where(predictions == Evaluation,1,0)
#             misclassified = np.where(predictions != Evaluation,1,0)
        #     # Calculate the misclassification rate and accuracy
#             accuracy = sum(evaluation)/len(evaluation)
#             print(accuracy)
#             misclassification = sum(misclassified)/len(misclassified)
        #     # Caclulate the error
            err=0
            err=1
    
            for i in range(len(idx)):
                if predictions[i] != Y[i]:
#                     err+=weights[idx[i]]
                    err+=1
#                     if Y[i] == 'no':
#                         err+=weights[idx[i]]*11
#                         err+=11

            
            err/=len(XX)
#             if err >= 1 or err==0:
#                 self.T=t+1
#                 break
#                 self.T+=1
#                 continue
#             err = np.sum(weights*misclassified)/np.sum(weights)



        #     # Calculate the alpha values
            alpha = 0.5*np.log((1-err)/err)
            print(err, alpha)

            alphas.append(alpha)
        #     # Update the weights wi --> These updated weights are used in the sample_weight parameter
        #     # for the training of the next decision stump. 
#             weights *= np.exp(alpha*misclassified)
            weights = np.array(weights)
            weights *= np.exp(alpha)
            j=0
            for i in range(len(idx)):
                if predictions[i] == Y[i]:
                    j+=1
                    weights[idx[i]]*=np.exp(-2*alpha)
            print(idx)
            t+=1
            #print('The Accuracy of the {0}. model is : '.format(t+1),accuracy*100,'%')
            #print('The missclassification rate is: ',misclassification*100,'%')
        self.alphas = alphas
        self.models = models
        
        print(self.alphas)
        return self
            
    def predict(self):
        X_test = self.test_dataset.iloc[: ,:]
        Y_test = self.test_dataset.iloc[:, -1].copy()
        Y_test[Y_test == 'yes'] = 1
        Y_test[Y_test == 'no'] = 0
#         print(self.dataset.iloc[1: -1])
    
        # With each model in the self.model list, make a prediction 
        
        accuracy = []
        predictions = []
        
        for alpha,model in zip(self.alphas,self.models):
            pred = np.array(test_tree(X_test, model)) # We use the predict method for the single decisiontreeclassifier models in the list
            pred[pred == 'yes'] = 1
            pred[pred == 'no'] = 0
            prediction = alpha*pred # We use the predict method for the single decisiontreeclassifier models in the list

            
#             prediction = alpha*model.predict(X_test) # We use the predict method for the single decisiontreeclassifier models in the list
            predictions.append(prediction)
            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test)/len(predictions[0]))
           
        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))
        print(self.accuracy)
        return self

model = Boosting(dataset,3 ,dataset_test)
model.fit()

model.predict()

for tree in model.models:
    pprint(tree)

# model.predict()

dataset_test["survived"].value_counts()

441/(441+204)
